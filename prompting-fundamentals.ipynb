{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n!pip install -U -q \"google-genai==1.7.0\"\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:18:29.269231Z","iopub.execute_input":"2025-04-01T10:18:29.269814Z","iopub.status.idle":"2025-04-01T10:18:37.166194Z","shell.execute_reply.started":"2025-04-01T10:18:29.269768Z","shell.execute_reply":"2025-04-01T10:18:37.164978Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import HTML, Markdown, display","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:19:24.730214Z","iopub.execute_input":"2025-04-01T10:19:24.730708Z","iopub.status.idle":"2025-04-01T10:19:26.463723Z","shell.execute_reply.started":"2025-04-01T10:19:24.730674Z","shell.execute_reply":"2025-04-01T10:19:26.462643Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from google.api_core import retry\n\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:29:38.631489Z","iopub.execute_input":"2025-04-01T10:29:38.631984Z","iopub.status.idle":"2025-04-01T10:29:38.638714Z","shell.execute_reply.started":"2025-04-01T10:29:38.631955Z","shell.execute_reply":"2025-04-01T10:29:38.636996Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:31:10.120935Z","iopub.execute_input":"2025-04-01T10:31:10.121341Z","iopub.status.idle":"2025-04-01T10:31:10.277108Z","shell.execute_reply.started":"2025-04-01T10:31:10.121315Z","shell.execute_reply":"2025-04-01T10:31:10.275795Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=\"Explain AI to me like I'm a kid.\")\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:31:55.190044Z","iopub.execute_input":"2025-04-01T10:31:55.190446Z","iopub.status.idle":"2025-04-01T10:31:57.744722Z","shell.execute_reply.started":"2025-04-01T10:31:55.190418Z","shell.execute_reply":"2025-04-01T10:31:57.743603Z"}},"outputs":[{"name":"stdout","text":"Imagine you have a really, really smart puppy, but it doesn't know anything yet. That's like AI!\n\nAI stands for Artificial Intelligence, which means making computers smart, just like us!\n\nInstead of teaching the puppy tricks with treats and repetition, we teach the computer by feeding it lots and lots of information, like pictures, words, and numbers.\n\nFor example, if you want to teach the computer to recognize cats, you would show it thousands of pictures of cats.  After seeing so many cats, the computer learns what cats usually look like: pointy ears, whiskers, a tail!\n\nThen, when you show the computer a new picture, it can say \"That's a cat!\" because it learned from all the pictures you showed it.\n\nSo, AI is like:\n\n*   **Teaching a computer to learn things.**\n*   **Giving the computer lots and lots of examples.**\n*   **Letting the computer use what it learned to do cool things!**\n\nAI helps us with lots of things, like:\n\n*   **Playing games (like chess or checkers).**\n*   **Helping us find videos we like to watch.**\n*   **Driving cars (sometimes, in the future!).**\n*   **Answering our questions (like Siri or Alexa).**\n\nAI is still learning and getting smarter every day, just like you! It's like a super smart student who's always learning new things!\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"Markdown(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:32:37.197447Z","iopub.execute_input":"2025-04-01T10:32:37.197998Z","iopub.status.idle":"2025-04-01T10:32:37.207298Z","shell.execute_reply.started":"2025-04-01T10:32:37.197957Z","shell.execute_reply":"2025-04-01T10:32:37.205989Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Imagine you have a really, really smart puppy, but it doesn't know anything yet. That's like AI!\n\nAI stands for Artificial Intelligence, which means making computers smart, just like us!\n\nInstead of teaching the puppy tricks with treats and repetition, we teach the computer by feeding it lots and lots of information, like pictures, words, and numbers.\n\nFor example, if you want to teach the computer to recognize cats, you would show it thousands of pictures of cats.  After seeing so many cats, the computer learns what cats usually look like: pointy ears, whiskers, a tail!\n\nThen, when you show the computer a new picture, it can say \"That's a cat!\" because it learned from all the pictures you showed it.\n\nSo, AI is like:\n\n*   **Teaching a computer to learn things.**\n*   **Giving the computer lots and lots of examples.**\n*   **Letting the computer use what it learned to do cool things!**\n\nAI helps us with lots of things, like:\n\n*   **Playing games (like chess or checkers).**\n*   **Helping us find videos we like to watch.**\n*   **Driving cars (sometimes, in the future!).**\n*   **Answering our questions (like Siri or Alexa).**\n\nAI is still learning and getting smarter every day, just like you! It's like a super smart student who's always learning new things!\n"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"chat = client.chats.create(model='gemini-2.0-flash', history=[])\nresponse = chat.send_message('Hello! My name is Zlork.')\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:32:58.398508Z","iopub.execute_input":"2025-04-01T10:32:58.398909Z","iopub.status.idle":"2025-04-01T10:32:58.962645Z","shell.execute_reply.started":"2025-04-01T10:32:58.398881Z","shell.execute_reply":"2025-04-01T10:32:58.961307Z"}},"outputs":[{"name":"stdout","text":"Hello Zlork! It's nice to meet you. How can I help you today?\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"response = chat.send_message('Can you tell me something interesting about dinosaurs?')\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:33:30.647126Z","iopub.execute_input":"2025-04-01T10:33:30.647568Z","iopub.status.idle":"2025-04-01T10:33:32.638379Z","shell.execute_reply.started":"2025-04-01T10:33:30.647511Z","shell.execute_reply":"2025-04-01T10:33:32.637060Z"}},"outputs":[{"name":"stdout","text":"Okay, here's another interesting fact about dinosaurs:\n\n**Dinosaurs lived on every continent, even Antarctica!**\n\nWhile the thought of dinosaurs thriving in a frozen wasteland might seem strange, fossils have been found in Antarctica that prove they were able to adapt to different climates across the globe.\n\n**Why is this fascinating?**\n\n*   **It shows the adaptability of dinosaurs:** Despite their size and perceived reptilian nature, dinosaurs were incredibly adaptable and could survive in a wider range of environments than we might initially think.\n*   **Antarctica was very different when dinosaurs lived there:** During the Mesozoic Era (when dinosaurs lived), Antarctica was much warmer and more temperate, with forests and rivers.\n*   **Finding fossils in Antarctica is challenging:** The harsh conditions and remote location make fossil discoveries in Antarctica especially significant and difficult. It requires specialized expeditions and equipment.\n\nSo, the next time you imagine dinosaurs, remember that they weren't just limited to tropical jungles or grassy plains - they even braved the prehistoric Antarctic!\n\nWould you like to hear yet another interesting fact about dinosaurs? I have lots! Perhaps you have a particular dinosaur in mind you would like me to tell you about?\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"response = chat.send_message('Do you remember what my name is?')\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:33:52.153644Z","iopub.execute_input":"2025-04-01T10:33:52.154052Z","iopub.status.idle":"2025-04-01T10:33:52.606874Z","shell.execute_reply.started":"2025-04-01T10:33:52.154024Z","shell.execute_reply":"2025-04-01T10:33:52.605647Z"}},"outputs":[{"name":"stdout","text":"Yes, your name is Zlork.\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"for model in client.models.list():\n  print(model.name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:34:23.180253Z","iopub.execute_input":"2025-04-01T10:34:23.180753Z","iopub.status.idle":"2025-04-01T10:34:23.264862Z","shell.execute_reply.started":"2025-04-01T10:34:23.180716Z","shell.execute_reply":"2025-04-01T10:34:23.263502Z"}},"outputs":[{"name":"stdout","text":"models/chat-bison-001\nmodels/text-bison-001\nmodels/embedding-gecko-001\nmodels/gemini-1.0-pro-vision-latest\nmodels/gemini-pro-vision\nmodels/gemini-1.5-pro-latest\nmodels/gemini-1.5-pro-001\nmodels/gemini-1.5-pro-002\nmodels/gemini-1.5-pro\nmodels/gemini-1.5-flash-latest\nmodels/gemini-1.5-flash-001\nmodels/gemini-1.5-flash-001-tuning\nmodels/gemini-1.5-flash\nmodels/gemini-1.5-flash-002\nmodels/gemini-1.5-flash-8b\nmodels/gemini-1.5-flash-8b-001\nmodels/gemini-1.5-flash-8b-latest\nmodels/gemini-1.5-flash-8b-exp-0827\nmodels/gemini-1.5-flash-8b-exp-0924\nmodels/gemini-2.5-pro-exp-03-25\nmodels/gemini-2.0-flash-exp\nmodels/gemini-2.0-flash\nmodels/gemini-2.0-flash-001\nmodels/gemini-2.0-flash-exp-image-generation\nmodels/gemini-2.0-flash-lite-001\nmodels/gemini-2.0-flash-lite\nmodels/gemini-2.0-flash-lite-preview-02-05\nmodels/gemini-2.0-flash-lite-preview\nmodels/gemini-2.0-pro-exp\nmodels/gemini-2.0-pro-exp-02-05\nmodels/gemini-exp-1206\nmodels/gemini-2.0-flash-thinking-exp-01-21\nmodels/gemini-2.0-flash-thinking-exp\nmodels/gemini-2.0-flash-thinking-exp-1219\nmodels/learnlm-1.5-pro-experimental\nmodels/gemma-3-4b-it\nmodels/gemma-3-12b-it\nmodels/gemma-3-27b-it\nmodels/embedding-001\nmodels/text-embedding-004\nmodels/gemini-embedding-exp-03-07\nmodels/gemini-embedding-exp\nmodels/aqa\nmodels/imagen-3.0-generate-002\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"from pprint import pprint\n\nfor model in client.models.list():\n  if model.name == 'models/gemini-2.0-flash':\n    pprint(model.to_json_dict())\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:34:52.660075Z","iopub.execute_input":"2025-04-01T10:34:52.660507Z","iopub.status.idle":"2025-04-01T10:34:52.767618Z","shell.execute_reply.started":"2025-04-01T10:34:52.660475Z","shell.execute_reply":"2025-04-01T10:34:52.766284Z"}},"outputs":[{"name":"stdout","text":"{'description': 'Gemini 2.0 Flash',\n 'display_name': 'Gemini 2.0 Flash',\n 'input_token_limit': 1048576,\n 'name': 'models/gemini-2.0-flash',\n 'output_token_limit': 8192,\n 'supported_actions': ['generateContent', 'countTokens'],\n 'tuned_model_info': {},\n 'version': '2.0'}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from google.genai import types\n\nshort_config = types.GenerateContentConfig(max_output_tokens=200)\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    config=short_config,\n    contents='Write a 500 word essay on Australian forest fires.')\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:38:16.691328Z","iopub.execute_input":"2025-04-01T10:38:16.691873Z","iopub.status.idle":"2025-04-01T10:38:18.184608Z","shell.execute_reply.started":"2025-04-01T10:38:16.691834Z","shell.execute_reply":"2025-04-01T10:38:18.183306Z"}},"outputs":[{"name":"stdout","text":"## The Scorched Earth: Understanding Australian Forest Fires\n\nAustralia's landscape, a tapestry woven with eucalyptus forests, grasslands, and arid deserts, is intrinsically linked to fire. For millennia, Aboriginal communities have used controlled burns to manage the landscape and promote biodiversity. However, in recent decades, Australian forest fires have escalated in intensity and frequency, transforming from a manageable element of the ecosystem to a devastating force of destruction. Understanding the complex interplay of climate change, land management practices, and fuel loads is crucial to mitigating future tragedies and preserving Australia's unique environment.\n\nClimate change is undoubtedly a significant driver of the increasing severity of Australian fires. Rising global temperatures contribute to prolonged droughts, which parch vegetation and transform it into highly flammable fuel. Heatwaves exacerbate the dryness, while shifting weather patterns bring stronger winds, spreading flames with alarming speed. The devastating \"Black Summer\" of 2019-20, which saw unprecedented levels of destruction and smoke pollution, serves as a stark reminder of the\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"response = client.models.generate_content(\n    model='gemini-2.0-flash',\n    config=short_config,\n    contents='Write a short poem on the importance of education in modern society.')\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:38:46.791070Z","iopub.execute_input":"2025-04-01T10:38:46.791486Z","iopub.status.idle":"2025-04-01T10:38:47.836049Z","shell.execute_reply.started":"2025-04-01T10:38:46.791458Z","shell.execute_reply":"2025-04-01T10:38:47.834687Z"}},"outputs":[{"name":"stdout","text":"In circuits bright, and codes untold,\nA modern world, both brave and bold.\nEducation's flame, a guiding light,\nTo pierce the shadows, make things right.\n\nFrom data streams to distant stars,\nKnowledge unlocks, breaks down the bars.\nWith skills to learn, and minds to grow,\nA brighter future starts to flow.\n\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"high_temp_config = types.GenerateContentConfig(temperature=2.0)\n\n\nfor _ in range(5):\n  response = client.models.generate_content(\n      model='gemini-2.0-flash',\n      config=high_temp_config,\n      contents='Pick a random colour... (respond in a single word)')\n\n  if response.text:\n    print(response.text, '-' * 25)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:39:43.235104Z","iopub.execute_input":"2025-04-01T10:39:43.235582Z","iopub.status.idle":"2025-04-01T10:39:45.509752Z","shell.execute_reply.started":"2025-04-01T10:39:43.235528Z","shell.execute_reply":"2025-04-01T10:39:45.508518Z"}},"outputs":[{"name":"stdout","text":"Turquoise\n -------------------------\nPurple\n -------------------------\nAzure.\n -------------------------\nAzure.\n -------------------------\nCerulean\n -------------------------\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"low_temp_config = types.GenerateContentConfig(temperature=0.0)\n\nfor _ in range(5):\n  response = client.models.generate_content(\n      model='gemini-2.0-flash',\n      config=low_temp_config,\n      contents='Pick a random colour... (respond in a single word)')\n\n  if response.text:\n    print(response.text, '-' * 25)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:40:45.140478Z","iopub.execute_input":"2025-04-01T10:40:45.140980Z","iopub.status.idle":"2025-04-01T10:40:47.265783Z","shell.execute_reply.started":"2025-04-01T10:40:45.140945Z","shell.execute_reply":"2025-04-01T10:40:47.264590Z"}},"outputs":[{"name":"stdout","text":"Azure\n -------------------------\nAzure\n -------------------------\nAzure\n -------------------------\nAzure\n -------------------------\nAzure\n -------------------------\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"model_config = types.GenerateContentConfig(\n    # These are the default values for gemini-2.0-flash.\n    temperature=1.0,\n    top_p=0.95,\n)\n\nstory_prompt = \"You are a creative writer. Write a short story about a cat who goes on an adventure.\"\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    config=model_config,\n    contents=story_prompt)\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:42:20.536462Z","iopub.execute_input":"2025-04-01T10:42:20.536962Z","iopub.status.idle":"2025-04-01T10:42:25.229179Z","shell.execute_reply.started":"2025-04-01T10:42:20.536929Z","shell.execute_reply":"2025-04-01T10:42:25.227929Z"}},"outputs":[{"name":"stdout","text":"Whiskers twitching, Clementine surveyed her kingdom. A sunbeam-drenched windowsill, a plush velvet cushion, a half-empty bowl of salmon pâté – all delightful, certainly, but utterly…predictable. Clementine, a ginger tabby with eyes the color of melted amber, yearned for something more.\n\nOne breezy afternoon, the back door, usually a fortress against the unknown, remained ajar. The scent of damp earth and wild honeysuckle wafted in, a siren’s call to Clementine’s adventurous spirit. Without a second thought, she slipped through the crack and into the great, green wilderness of the backyard.\n\nThe world exploded with newness. Butterflies fluttered like living jewels, and grasshoppers chirped symphonies in the tall grass. Clementine stalked through the jungle of flowerbeds, a miniature tigress on the hunt for excitement. She batted at a particularly plump bumblebee (who buzzed a stern warning), and scaled a trellis heavy with fragrant wisteria.\n\nHer adventure led her to the edge of the woods bordering her yard. Temptation, in the form of rustling leaves and the chirping of unseen birds, beckoned. Clementine, emboldened by her earlier conquests, plunged into the undergrowth.\n\nThe woods were a labyrinth of smells and sounds. Squirrels chattered insults from high branches, and the sun dappled through the leaves, creating shifting patterns of light and shadow. Clementine chased a particularly audacious chipmunk, weaving through the trees until she was hopelessly, thrillingly, lost.\n\nPanic began to prickle at her fur. The shadows lengthened, and the cheerful chirping of birds gave way to the eerie hoot of an owl in the distance. Clementine, alone in the darkening woods, felt a pang of regret for her comfortable windowsill.\n\nThen, she heard it: a familiar, comforting sound. A soft, melodic whistle. Her human! He was calling her name, his voice laced with worry.\n\nWith renewed vigor, Clementine raced towards the sound. She stumbled over roots, scratched her nose on prickly bushes, but she didn’t stop. Finally, she burst out of the woods and into a small clearing. There he was, her human, his face etched with relief.\n\nHe scooped her up in his arms, burying his face in her fur. \"Clementine! Where have you been? You scared me half to death!\"\n\nClementine purred, a rumbling vibration of contentment. The adventure had been thrilling, but the comfort of her human's arms was even better.\n\nAs he carried her back towards the house, Clementine glanced back at the woods. The shadows seemed less menacing now, and the rustling leaves whispered tales of adventure. She knew she would return someday. But for now, the warmth of the sunbeam-drenched windowsill, the plush velvet cushion, and the salmon pâté never tasted so good. Clementine had learned that the greatest adventure was knowing you had a safe and loving home to come back to. And maybe, just maybe, she’d keep the back door closed next time.\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"model_config = types.GenerateContentConfig(\n    temperature=0.1,\n    top_p=1,\n    max_output_tokens=5,\n)\n\nzero_shot_prompt = \"\"\"Classify movie reviews as POSITIVE, NEUTRAL or NEGATIVE.\nReview: I am okay with the movie.\nSentiment: \"\"\"\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    config=model_config,\n    contents=zero_shot_prompt)\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:45:12.624944Z","iopub.execute_input":"2025-04-01T10:45:12.625425Z","iopub.status.idle":"2025-04-01T10:45:13.196488Z","shell.execute_reply.started":"2025-04-01T10:45:12.625388Z","shell.execute_reply":"2025-04-01T10:45:13.195431Z"}},"outputs":[{"name":"stdout","text":"NEUTRAL\n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import enum\n\nclass Sentiment(enum.Enum):\n    POSITIVE = \"positive\"\n    NEUTRAL = \"neutral\"\n    NEGATIVE = \"negative\"\n\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    config=types.GenerateContentConfig(\n        response_mime_type=\"text/x.enum\",\n        response_schema=Sentiment\n    ),\n    contents=\"I am feeling happy\")\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:46:16.827325Z","iopub.execute_input":"2025-04-01T10:46:16.827873Z","iopub.status.idle":"2025-04-01T10:46:17.301417Z","shell.execute_reply.started":"2025-04-01T10:46:16.827831Z","shell.execute_reply":"2025-04-01T10:46:17.300309Z"}},"outputs":[{"name":"stdout","text":"positive\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"enum_response = response.parsed\nprint(enum_response)\nprint(type(enum_response))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:47:10.262713Z","iopub.execute_input":"2025-04-01T10:47:10.263167Z","iopub.status.idle":"2025-04-01T10:47:10.270044Z","shell.execute_reply.started":"2025-04-01T10:47:10.263138Z","shell.execute_reply":"2025-04-01T10:47:10.268366Z"}},"outputs":[{"name":"stdout","text":"Sentiment.POSITIVE\n<enum 'Sentiment'>\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"few_shot_prompt = \"\"\"Parse a customer's pizza order into valid JSON:\n\nEXAMPLE:\nI want a small pizza with cheese, tomato sauce, and pepperoni.\nJSON Response:\n```\n{\n\"size\": \"small\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"tomato sauce\", \"pepperoni\"]\n}\n```\n\nEXAMPLE:\nCan I get a large pizza with tomato sauce, basil and mozzarella\nJSON Response:\n```\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"tomato sauce\", \"basil\", \"mozzarella\"]\n}\n```\n\nORDER:\n\"\"\"\n\ncustomer_order = \"Give me a large with cheese & pineapple\"\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    config=types.GenerateContentConfig(\n        temperature=0.1,\n        top_p=1,\n        max_output_tokens=250,\n    ),\n    contents=[few_shot_prompt, customer_order])\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:48:36.023766Z","iopub.execute_input":"2025-04-01T10:48:36.024209Z","iopub.status.idle":"2025-04-01T10:48:36.620444Z","shell.execute_reply.started":"2025-04-01T10:48:36.024181Z","shell.execute_reply":"2025-04-01T10:48:36.619267Z"}},"outputs":[{"name":"stdout","text":"```json\n{\n\"size\": \"large\",\n\"type\": \"normal\",\n\"ingredients\": [\"cheese\", \"pineapple\"]\n}\n```\n\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"import typing_extensions as typing\n\nclass PizzaOrder(typing.TypedDict):\n    size: str\n    ingredients: list[str]\n    type: str\n\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    config=types.GenerateContentConfig(\n        temperature=0.1,\n        response_mime_type=\"application/json\",\n        response_schema=PizzaOrder,\n    ),\n    contents=\"Can I have a large dessert pizza with apple and chocolate\")\n\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:50:09.309266Z","iopub.execute_input":"2025-04-01T10:50:09.309774Z","iopub.status.idle":"2025-04-01T10:50:10.249346Z","shell.execute_reply.started":"2025-04-01T10:50:09.309736Z","shell.execute_reply":"2025-04-01T10:50:10.248141Z"}},"outputs":[{"name":"stdout","text":"{\n  \"size\": \"large\",\n  \"ingredients\": [\"apple\", \"chocolate\"],\n  \"type\": \"dessert\"\n}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"prompt = \"\"\"When I was 4 years old, my partner was 3 times my age. Now, I\nam 20 years old. How old is my partner? Return the answer directly.\"\"\"\n\nresponse = client.models.generate_content(\n    model='gemini-2.0-flash',\n    contents=prompt)\n\nprint(response.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:52:27.809093Z","iopub.execute_input":"2025-04-01T10:52:27.809645Z","iopub.status.idle":"2025-04-01T10:52:28.479295Z","shell.execute_reply.started":"2025-04-01T10:52:27.809601Z","shell.execute_reply":"2025-04-01T10:52:28.478096Z"}},"outputs":[{"name":"stdout","text":"52\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"question = \"\"\"Question\nWho was the youngest author listed on the transformers NLP paper?\n\"\"\"\n\n# You will perform the Action; so generate up to, but not including, the Observation.\nreact_config = types.GenerateContentConfig(\n    stop_sequences=[\"\\nObservation\"],\n    system_instruction=model_instructions + example1 + example2,\n)\n\n# Create a chat that has the model instructions and examples pre-seeded.\nreact_chat = client.chats.create(\n    model='gemini-2.0-flash',\n    config=react_config,\n)\n\nresp = react_chat.send_message(question)\nprint(resp.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:55:58.612621Z","iopub.execute_input":"2025-04-01T10:55:58.613094Z","iopub.status.idle":"2025-04-01T10:55:58.638563Z","shell.execute_reply.started":"2025-04-01T10:55:58.613065Z","shell.execute_reply":"2025-04-01T10:55:58.636647Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-0995c46220ca>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m react_config = types.GenerateContentConfig(\n\u001b[1;32m      7\u001b[0m     \u001b[0mstop_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"\\nObservation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msystem_instruction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_instructions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexample1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexample2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_instructions' is not defined"],"ename":"NameError","evalue":"name 'model_instructions' is not defined","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"observation = \"\"\"Observation 1\n[1706.03762] Attention Is All You Need\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\nWe propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\n\"\"\"\nresp = react_chat.send_message(observation)\nprint(resp.text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:56:40.479284Z","iopub.execute_input":"2025-04-01T10:56:40.479715Z","iopub.status.idle":"2025-04-01T10:56:40.496849Z","shell.execute_reply.started":"2025-04-01T10:56:40.479687Z","shell.execute_reply":"2025-04-01T10:56:40.495108Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-ebea098c3192>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mWe\u001b[0m \u001b[0mpropose\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0msimple\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0marchitecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbased\u001b[0m \u001b[0msolely\u001b[0m \u001b[0mon\u001b[0m \u001b[0mattention\u001b[0m \u001b[0mmechanisms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdispensing\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mrecurrence\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconvolutions\u001b[0m \u001b[0mentirely\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreact_chat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'react_chat' is not defined"],"ename":"NameError","evalue":"name 'react_chat' is not defined","output_type":"error"}],"execution_count":43},{"cell_type":"code","source":"import io\nfrom IPython.display import Markdown, clear_output\n\n\nresponse = client.models.generate_content_stream(\n    model='gemini-2.0-flash-thinking-exp',\n    contents='Who was the youngest author listed on the transformers NLP paper?',\n)\n\nbuf = io.StringIO()\nfor chunk in response:\n    buf.write(chunk.text)\n    # Display the response as it is streamed\n    print(chunk.text, end='')\n\n# And then render the finished response as formatted markdown.\nclear_output()\nMarkdown(buf.getvalue())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T10:57:23.908326Z","iopub.execute_input":"2025-04-01T10:57:23.908837Z","iopub.status.idle":"2025-04-01T10:57:33.298355Z","shell.execute_reply.started":"2025-04-01T10:57:23.908798Z","shell.execute_reply":"2025-04-01T10:57:33.297013Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The youngest author listed on the \"Attention is All You Need\" paper (the Transformer NLP paper) is likely **Aidan N. Gomez**.\n\nHere's why:\n\n* **Aidan N. Gomez** was a graduate student at the University of Oxford at the time of publication (2017). Graduate students are typically younger than professors, research scientists, and other established researchers.\n* **Niki Parmar** was also a graduate student at the University of Southern California (USC) at the time. She is also likely to be among the youngest.\n\nWhile it's impossible to know the exact ages of all authors at the time of publication without their personal information, graduate students are generally the youngest demographic in academic research teams.  Both Aidan N. Gomez and Niki Parmar fit this category.\n\n**Therefore, Aidan N. Gomez is a very strong candidate for the youngest author.**  Niki Parmar is also highly likely to be in the same age range and could also be considered one of the youngest, if not the youngest.\n\nIt's important to note that \"youngest\" is an inference based on typical academic career paths and publicly available information.  Without knowing their exact birthdates, we can't be 100% certain, but based on their roles as graduate students, they are the most probable youngest authors."},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}